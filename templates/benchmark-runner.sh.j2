#!/bin/bash
# =============================================================================
# MongoDB Performance Benchmark Runner
# =============================================================================
# Runs performance benchmarks on MongoDB.
# Generated by Ansible - Do not edit manually
# =============================================================================

set -euo pipefail

RESULTS_DIR="/opt/mongodb-chaos/results"
LOG_FILE="${RESULTS_DIR}/benchmark-$(date +%Y%m%d_%H%M%S).log"
MONGO_PORT="{{ mongodb_port }}"

{% if mongodb_security_auth_enabled %}
AUTH_OPTS="--username {{ mongodb_admin_user }} --password {{ mongodb_admin_password }} --authenticationDatabase admin"
{% else %}
AUTH_OPTS=""
{% endif %}

# Benchmark configuration
NUM_DOCS=${1:-10000}
BATCH_SIZE=${2:-100}
NUM_THREADS=${3:-4}

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "${LOG_FILE}"
}

log "Starting MongoDB Performance Benchmark"
log "======================================="
log "Documents: ${NUM_DOCS}"
log "Batch Size: ${BATCH_SIZE}"
log "Threads: ${NUM_THREADS}"

# Create benchmark database
mongosh --host localhost --port ${MONGO_PORT} ${AUTH_OPTS} \
    --eval "db.getSiblingDB('benchmark').dropDatabase()" --quiet 2>/dev/null || true

# Write Benchmark
log ""
log "Running Write Benchmark..."
WRITE_START=$(date +%s.%N)

mongosh --host localhost --port ${MONGO_PORT} ${AUTH_OPTS} --eval "
    var db = db.getSiblingDB('benchmark');
    var numDocs = ${NUM_DOCS};
    var batchSize = ${BATCH_SIZE};
    var batch = [];
    
    for (var i = 0; i < numDocs; i++) {
        batch.push({
            _id: i,
            data: 'benchmark_data_' + i,
            timestamp: new Date(),
            random: Math.random(),
            nested: {
                field1: 'value1',
                field2: i * 100,
                array: [1, 2, 3, 4, 5]
            }
        });
        
        if (batch.length >= batchSize) {
            db.benchmark_collection.insertMany(batch, {ordered: false});
            batch = [];
        }
    }
    
    if (batch.length > 0) {
        db.benchmark_collection.insertMany(batch, {ordered: false});
    }
    
    print('Write complete');
" --quiet 2>/dev/null

WRITE_END=$(date +%s.%N)
WRITE_TIME=$(echo "${WRITE_END} - ${WRITE_START}" | bc)
WRITE_OPS=$(echo "scale=2; ${NUM_DOCS} / ${WRITE_TIME}" | bc)

log "Write Benchmark Results:"
log "  - Total Time: ${WRITE_TIME} seconds"
log "  - Operations/sec: ${WRITE_OPS}"

# Read Benchmark (Random Reads)
log ""
log "Running Read Benchmark..."
READ_START=$(date +%s.%N)

mongosh --host localhost --port ${MONGO_PORT} ${AUTH_OPTS} --eval "
    var db = db.getSiblingDB('benchmark');
    var numReads = ${NUM_DOCS};
    var maxId = ${NUM_DOCS} - 1;
    
    for (var i = 0; i < numReads; i++) {
        var randomId = Math.floor(Math.random() * maxId);
        db.benchmark_collection.findOne({_id: randomId});
    }
    
    print('Read complete');
" --quiet 2>/dev/null

READ_END=$(date +%s.%N)
READ_TIME=$(echo "${READ_END} - ${READ_START}" | bc)
READ_OPS=$(echo "scale=2; ${NUM_DOCS} / ${READ_TIME}" | bc)

log "Read Benchmark Results:"
log "  - Total Time: ${READ_TIME} seconds"
log "  - Operations/sec: ${READ_OPS}"

# Update Benchmark
log ""
log "Running Update Benchmark..."
UPDATE_START=$(date +%s.%N)

mongosh --host localhost --port ${MONGO_PORT} ${AUTH_OPTS} --eval "
    var db = db.getSiblingDB('benchmark');
    var numUpdates = Math.floor(${NUM_DOCS} / 10);
    var maxId = ${NUM_DOCS} - 1;
    
    for (var i = 0; i < numUpdates; i++) {
        var randomId = Math.floor(Math.random() * maxId);
        db.benchmark_collection.updateOne(
            {_id: randomId},
            {\$set: {updated: true, updateTime: new Date()}}
        );
    }
    
    print('Update complete');
" --quiet 2>/dev/null

UPDATE_END=$(date +%s.%N)
UPDATE_TIME=$(echo "${UPDATE_END} - ${UPDATE_START}" | bc)
UPDATE_COUNT=$((NUM_DOCS / 10))
UPDATE_OPS=$(echo "scale=2; ${UPDATE_COUNT} / ${UPDATE_TIME}" | bc)

log "Update Benchmark Results:"
log "  - Total Time: ${UPDATE_TIME} seconds"
log "  - Operations/sec: ${UPDATE_OPS}"

# Aggregation Benchmark
log ""
log "Running Aggregation Benchmark..."
AGG_START=$(date +%s.%N)

mongosh --host localhost --port ${MONGO_PORT} ${AUTH_OPTS} --eval "
    var db = db.getSiblingDB('benchmark');
    
    db.benchmark_collection.aggregate([
        {\$match: {random: {\$gte: 0.5}}},
        {\$group: {_id: null, count: {\$sum: 1}, avgRandom: {\$avg: '\$random'}}},
        {\$project: {_id: 0, count: 1, avgRandom: 1}}
    ]).toArray();
    
    print('Aggregation complete');
" --quiet 2>/dev/null

AGG_END=$(date +%s.%N)
AGG_TIME=$(echo "${AGG_END} - ${AGG_START}" | bc)

log "Aggregation Benchmark Results:"
log "  - Total Time: ${AGG_TIME} seconds"

# Cleanup
mongosh --host localhost --port ${MONGO_PORT} ${AUTH_OPTS} \
    --eval "db.getSiblingDB('benchmark').dropDatabase()" --quiet 2>/dev/null || true

log ""
log "Benchmark Complete"
log "=================="

# Save results
cat > "${RESULTS_DIR}/benchmark-latest.json" << EOF
{
    "test": "performance-benchmark",
    "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "configuration": {
        "num_documents": ${NUM_DOCS},
        "batch_size": ${BATCH_SIZE}
    },
    "results": {
        "write": {
            "time_seconds": ${WRITE_TIME},
            "ops_per_second": ${WRITE_OPS}
        },
        "read": {
            "time_seconds": ${READ_TIME},
            "ops_per_second": ${READ_OPS}
        },
        "update": {
            "time_seconds": ${UPDATE_TIME},
            "ops_per_second": ${UPDATE_OPS}
        },
        "aggregation": {
            "time_seconds": ${AGG_TIME}
        }
    }
}
EOF

cat "${RESULTS_DIR}/benchmark-latest.json"

exit 0
